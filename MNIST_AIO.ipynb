{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOc0VicMmhsK0J9ROqFuY1c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muzsek/MNIST/blob/main/MNIST_AIO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hXqRDcheb5g6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor()"
      ],
      "metadata": {
        "id": "UJtPp9i7cK94"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.MNIST(root='./data', train = True, download = True, transform = transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train = False, download = True, transform = transform)"
      ],
      "metadata": {
        "id": "_d6QXL0acOz4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e67b734d-64a2-4ff2-c29d-2ea0f400c6ec"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.08MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 134kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.27MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.52MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size = 64, shuffle = True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = 64, shuffle = True)"
      ],
      "metadata": {
        "id": "feo5f6kwcha8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.shape}\")\n",
        "print(f\"Labels batch shape: {train_labels.shape}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "id": "KEhjkmNjdK0U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "ea7fe601-58eb-49bb-aa88-33f458eabe4c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([64])\n",
            "Label: 6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_fn(y_true, y_pred):\n",
        "    \"\"\"Calculates accuracy between truth labels and predictions.\n",
        "\n",
        "    Args:\n",
        "        y_true (torch.Tensor): Truth labels for predictions.\n",
        "        y_pred (torch.Tensor): Predictions to be compared to predictions.\n",
        "\n",
        "    Returns:\n",
        "        [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n",
        "    \"\"\"\n",
        "    correct = torch.eq(y_true, y_pred).sum().item()\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc"
      ],
      "metadata": {
        "id": "4Pqtt7cc7n-Q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "      super().__init__()\n",
        "      self.conv1_block = nn.Sequential(\n",
        "          nn.Conv2d(in_channels = 1, out_channels =32, kernel_size = 3, stride = 1),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size = 1, stride = 2)\n",
        "      )\n",
        "      self.conv2_block = nn.Sequential(\n",
        "          nn.Conv2d(in_channels = 32, out_channels =16, kernel_size = 3, stride = 1),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "      )\n",
        "      self.classifier = nn.Sequential(\n",
        "          nn.Flatten(),\n",
        "          nn.Linear(in_features=16*5*5,\n",
        "          out_features=10)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "      x = self.conv1_block(x)\n",
        "      #print(x.shape)\n",
        "      x = self.conv2_block(x)\n",
        "      #print(x.shape)\n",
        "      x = self.classifier(x)\n",
        "      #print(x.shape)\n",
        "      return x"
      ],
      "metadata": {
        "id": "UF9uU-7o4yDe"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "c5_U1s4WBNju"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0 = CNN().to(device)\n",
        "model_0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTlT86Lm5Suv",
        "outputId": "558d6ac5-366d-46c6-e9c0-1f27b920c0b6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1_block): Sequential(\n",
              "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv2_block): Sequential(\n",
              "    (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=400, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params = model_0.parameters(), lr = 0.001)\n",
        "\n"
      ],
      "metadata": {
        "id": "lQqXVFmL2RAG"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "epochs = 10\n",
        "train_loss = 0\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch: {epoch}\\n----------\")\n",
        "    for batch, (X, y) in enumerate(train_dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        model_0.train()\n",
        "        y_pred = model_0(X)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss.item()\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch % 400 == 0:\n",
        "          print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
        "          print(f\"Loss: {loss}\")\n",
        "\n",
        "        train_loss /= len(train_dataloader)\n",
        "\n",
        "        test_loss, test_acc = 0, 0\n",
        "    model_0.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X, y in test_dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            # 1. Forward pass\n",
        "            test_pred = model_0(X)\n",
        "\n",
        "            # 2. Calculate loss (accumulatively)\n",
        "            test_loss += loss_fn(test_pred, y) # accumulatively add up the loss per epoch\n",
        "\n",
        "            # 3. Calculate accuracy (preds need to be same as y_true)\n",
        "            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "        # Calculations on test metrics need to happen inside torch.inference_mode()\n",
        "        # Divide total test loss by length of test dataloader (per batch)\n",
        "        test_loss /= len(test_dataloader)\n",
        "\n",
        "        # Divide total accuracy by length of test dataloader (per batch)\n",
        "        test_acc /= len(test_dataloader)\n",
        "\n",
        "    ## Print out what's happening\n",
        "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n Accuracy:{test_acc:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WSywZ4os5WL5",
        "outputId": "41035427-ed97-4da2-fb09-d2faa9658214"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "----------\n",
            "Looked at 0/60000 samples\n",
            "Loss: 2.330192804336548\n",
            "Looked at 25600/60000 samples\n",
            "Loss: 0.24269622564315796\n",
            "Looked at 51200/60000 samples\n",
            "Loss: 0.05164086073637009\n",
            "\n",
            "Train loss: 0.00020 | Test loss: 0.10040, Test acc: 96.95%\n",
            " Accuracy:96.95\n",
            "Epoch: 1\n",
            "----------\n",
            "Looked at 0/60000 samples\n",
            "Loss: 0.11316309869289398\n",
            "Looked at 25600/60000 samples\n",
            "Loss: 0.025378450751304626\n",
            "Looked at 51200/60000 samples\n",
            "Loss: 0.03198694437742233\n",
            "\n",
            "Train loss: 0.00004 | Test loss: 0.06345, Test acc: 98.14%\n",
            " Accuracy:98.14\n",
            "Epoch: 2\n",
            "----------\n",
            "Looked at 0/60000 samples\n",
            "Loss: 0.0685749277472496\n",
            "Looked at 25600/60000 samples\n",
            "Loss: 0.044943131506443024\n",
            "Looked at 51200/60000 samples\n",
            "Loss: 0.07892325520515442\n",
            "\n",
            "Train loss: 0.00009 | Test loss: 0.06126, Test acc: 97.99%\n",
            " Accuracy:97.99\n",
            "Epoch: 3\n",
            "----------\n",
            "Looked at 0/60000 samples\n",
            "Loss: 0.03534361347556114\n",
            "Looked at 25600/60000 samples\n",
            "Loss: 0.02150440588593483\n",
            "Looked at 51200/60000 samples\n",
            "Loss: 0.038910187780857086\n",
            "\n",
            "Train loss: 0.00003 | Test loss: 0.04873, Test acc: 98.46%\n",
            " Accuracy:98.46\n",
            "Epoch: 4\n",
            "----------\n",
            "Looked at 0/60000 samples\n",
            "Loss: 0.047277793288230896\n",
            "Looked at 25600/60000 samples\n",
            "Loss: 0.1312328726053238\n",
            "Looked at 51200/60000 samples\n",
            "Loss: 0.04405157268047333\n",
            "\n",
            "Train loss: 0.00002 | Test loss: 0.04841, Test acc: 98.49%\n",
            " Accuracy:98.49\n",
            "Epoch: 5\n",
            "----------\n",
            "Looked at 0/60000 samples\n",
            "Loss: 0.018728600814938545\n",
            "Looked at 25600/60000 samples\n",
            "Loss: 0.0022313345689326525\n",
            "Looked at 51200/60000 samples\n",
            "Loss: 0.2062288522720337\n",
            "\n",
            "Train loss: 0.00001 | Test loss: 0.05124, Test acc: 98.41%\n",
            " Accuracy:98.41\n",
            "Epoch: 6\n",
            "----------\n",
            "Looked at 0/60000 samples\n",
            "Loss: 0.08052340894937515\n",
            "Looked at 25600/60000 samples\n",
            "Loss: 0.03146922588348389\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-981495827.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m400\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m                             )\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    242\u001b[0m             )\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    245\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    877\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_div_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq_sqrt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_add_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq_sqrt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m             torch._foreach_addcdiv_(\n\u001b[1;32m    708\u001b[0m                 \u001b[0mdevice_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_exp_avgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg_sq_sqrt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gdqFguIj5nGB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}